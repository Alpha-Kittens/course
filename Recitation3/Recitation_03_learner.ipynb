{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# RECITATION 3: Fitting and `LMFIT` Software\n",
    "\n",
    "<br>\n",
    "<!--end-block--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 3.0 Overview of Learning Objectives\n",
    "\n",
    "In this recitation we will explore the following objectives:\n",
    "\n",
    "- Fitting with the software package `LMFIT`\n",
    "- A second `LMFIT` example\n",
    "- Fitting with complicated models, like project 1\n",
    "- How to interpret bugs using `LMFIT`\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 3.1 Using `LMFIT` to fit to data\n",
    "\n",
    "To get some practice fitting, suppose you have some data coming from the function $y=2x$. We'll fit a model function of $y=mx+b$\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's generate some example data with made-up systematic uncertainties. These uncertainties are assumed to be the standard deviations of normal distributions (a common assumption). Therefore, we draw each data point $y_i$ from a normal distribution with standard deviation equal to the uncertainty of point $i$ and mean $2 x_i$.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(421421)\n",
    "\n",
    "xi = np.array([2,3,4,5,6,7])\n",
    "yi = 2*xi\n",
    "\n",
    "y_unc = np.array([0.3, 0.4, 0.45, 0.35, 0.6, 0.5])\n",
    "yi = yi + np.random.randn(len(xi))*y_unc\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(421421)\n",
    "\n",
    "xi = np.array([2,3,4,5,6,7])\n",
    "yi = 2*xi\n",
    "\n",
    "y_unc = np.array([0.3, 0.4, 0.45, 0.35, 0.6, 0.5])\n",
    "yi = yi + np.random.randn(len(xi))*y_unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Plot the data and its error bars.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#your code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(xi, yi)\n",
    "plt.errorbar(xi, yi, yerr=y_unc, linestyle='none')\n",
    "plt.plot(xi, 2 * xi);\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "We'll make a model using `LMFIT` to represent the data. Models can either be selected from a [large list of functions](https://lmfit.github.io/lmfit-py/builtin_models.html) already set up by `LMFIT`, or you can make them yourself. Here we use a preset linear model.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "from lmfit.models import LinearModel\n",
    "model = LinearModel()\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import LinearModel\n",
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "In tomorrow's lecture, you'll learn about the math behind fitting. But for now, let's let `LMFIT` black box it for us. Just know that `LMFIT` is doing a minimization algorithm behind the scenes.\n",
    "\n",
    "<b>Important:</b> set the weights equal to one over the systematic uncertainty. Not the uncertainty itself, and not the variance.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "result = model.fit(yi, x=xi, weights=1/yerr);\n",
    "\n",
    "print(result.fit_report())\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(yi, x=xi, weights=1/y_unc);\n",
    "\n",
    "print(result.fit_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "\n",
    "Look in the `Variables` section: we have a slope of about 2 and an intercept of about zero, consistent with the true model! Very helpfully, `LMFIT` also gives you uncertainties on the fit parameters. You'll learn how `LMFIT` does this tomorrow, as well as what the `chi-square` and `reduced chi-square` entries are.\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "There's one more thing to do: it's always a good idea to verify that your model actually fits your data. So let's plot the data together with the model.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "result.plot();\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "\n",
    "You can see that the model fits the data very well in the bottom plot, and the top plot demonstrates that deviations of the data from the model are random; they don't seem correlated with $x$ nor with each other. This is a good thing, because `LMFIT` assumed that the data points were uncorrelated with each other when performing the fit.\n",
    "\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 3.2 Another `LMFIT` example\n",
    "\n",
    "Fitting using a pre-determined model is all well and good, but how do you fit to data using your own model function?\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's arbitrarily choose the function\n",
    "$$f(x) = \\frac{\\cos(kx)}{x^a}$$\n",
    "as our model, with free parameters $k > 0$ and $a > 0$.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "import numpy as np\n",
    "\n",
    "def model_fn(x, k, a):# independent variable must be first argument\n",
    "    return np.cos(k * x) / x**a\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def model_fn(x, k, a):# independent variable must be first argument\n",
    "    return np.cos(k * x) / x**a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Generate some synthetic data using this model function, with 20 $x$ coordinates spaced evenly in $(0.1, \\pi]$. Use true values of $k=\\pi$ and $a=1$.\n",
    "\n",
    "Generate systematic uncertainty from a uniformly random distribution in the range $[0.1, 0.5]$ (`np.random.random()`). Assume that this uncertainty is the standard deviation of a normal distribution for the sake of randomizing your data (`np.random.randn()`).\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "import numpy as np\n",
    "np.random.seed(2345789)\n",
    "\n",
    "TRUE_K = np.pi\n",
    "TRUE_A = 1\n",
    "\n",
    "x = np.linspace(-4 * np.pi, 4 * np.pi, 20)\n",
    "y = #your code here\n",
    "yerr = #your code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "import numpy as np\n",
    "np.random.seed(2345789)\n",
    "\n",
    "TRUE_K = np.pi\n",
    "TRUE_A = 1\n",
    "\n",
    "x = np.linspace(0.1, np.pi, 20)\n",
    "y = model_fn(x, TRUE_K, TRUE_A)\n",
    "\n",
    "y_unc = 0.1 + 0.4 * np.random.random(len(x))\n",
    "y = y + np.random.randn(len(x)) * y_unc;\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2345789)\n",
    "\n",
    "TRUE_K = np.pi\n",
    "TRUE_A = 1\n",
    "\n",
    "x = np.linspace(-4 * np.pi, 4 * np.pi, 20)\n",
    "y = #your code here\n",
    "yerr = #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Now plot your data with error bars and the true function to ensure they match.\n",
    "<!--\n",
    "#initial code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#your code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(x, y, y_unc, linestyle='none')\n",
    "plt.plot(x, model_fn(x, TRUE_K, TRUE_A), label=\"true\")\n",
    "plt.scatter(x, y, label=\"data\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Now we need to give this model to `LMFIT`. This involves making a `Model` object, and giving it a `Parameters` object to describe the model parameters.\n",
    "\n",
    "Each parameter has `min`, `max`, and `value` arguments that specify the minimum allowable value, the maximum value, and the initial value respectively. None of these are required, but it's often a good idea to put them in if you expect your values to be within a certain range.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "model = Model(model_fn)\n",
    "\n",
    "params = Parameters()\n",
    "params.add('k', min=0, max=5, value=1)\n",
    "params.add('a', min=0, max=3, value=2)\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model, Parameters\n",
    "\n",
    "model = Model(model_fn)\n",
    "\n",
    "params = Parameters()\n",
    "params.add('k', min=0, max=5, value=1)\n",
    "params.add('a', min=0, max=3, value=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Finally, let's run the fit! We reuse the code from the previous example, but we have to pass `params` into the fit function this time.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "result = model.fit(y, params, x=x, weights=1/yerr);\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "result.plot();\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(y, params, x=x, weights=1/y_unc);\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Do your fit results agree with the true values? Which was determined with higher precision: $k$ or $a$? Does this make sense given your knowledge of the model function and the systematic uncertainty?\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "They do agree. $a$ can be fitted with higher precision because it controls the height of the first data point very precisely; a small change in $a$ will change the height of the first data point dramatically. However, $k$ is dominated by the data points at large $x$, which have small $y$ values compared to their error bars.\n",
    "-->\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 3.3 Complicated models\n",
    "\n",
    "You'll be using `LMFIT` for project 1 on a complicated gravitational wave model. This section is designed to grapple with some of the same challenges you'll grapple with in project 1, so that you have some practice.\n",
    "\n",
    "We'll look at a fit model which is similar to a black hole merger waveform.\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Below is a complicated model function with six parameters. Add code to generate true data from the function and store it as true_yi (do not include any systematic uncertainties). Then plot your data to see what the waveform looks like. Do you see the similarity to a black hole merger?\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0x98a09fe)\n",
    "\n",
    "def complicated_model_fn(x, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
    "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x, 0)**2 / omega_sigma)) + omega_0\n",
    "    lambdas = np.array([lambda_plus if xvalue > 0 else lambda_minus for xvalue in x])\n",
    "    amplitude = max_amp * np.exp(-abs(x) / lambdas)\n",
    "    return amplitude * np.cos(omega * x)\n",
    "\n",
    "LAMBDA_PLUS_TRUE = 1.0\n",
    "LAMBDA_MINUS_TRUE = 4\n",
    "MAX_AMP_TRUE = 1.2\n",
    "OMEGA_0_TRUE = 3.0\n",
    "OMEGA_MAX_TRUE = 6.0\n",
    "OMEGA_SIGMA_TRUE = 4.0\n",
    "\n",
    "xi = np.linspace(-15, 5, 200)\n",
    "true_yi = # your code here\n",
    "\n",
    "# your plotting code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0x98a09fe)\n",
    "\n",
    "def complicated_model_fn(x, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
    "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x, 0)**2 / omega_sigma)) + omega_0\n",
    "    lambdas = np.array([lambda_plus if xvalue > 0 else lambda_minus for xvalue in x])\n",
    "    amplitude = max_amp * np.exp(-abs(x) / lambdas)\n",
    "    return amplitude * np.cos(omega * x)\n",
    "\n",
    "LAMBDA_PLUS_TRUE = 1.0\n",
    "LAMBDA_MINUS_TRUE = 4\n",
    "MAX_AMP_TRUE = 1.2\n",
    "OMEGA_0_TRUE = 3.0\n",
    "OMEGA_MAX_TRUE = 6.0\n",
    "OMEGA_SIGMA_TRUE = 4.0\n",
    "\n",
    "xi = np.linspace(-15, 5, 200)\n",
    "true_yi = complicated_model_fn(xi, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE, OMEGA_0_TRUE,\n",
    "                                   OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
    "\n",
    "plt.plot(xi, true_yi)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\");\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0x98a09fe)\n",
    "\n",
    "def complicated_model_fn(x, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
    "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x, 0)**2 / omega_sigma)) + omega_0\n",
    "    lambdas = np.array([lambda_plus if xvalue > 0 else lambda_minus for xvalue in x])\n",
    "    amplitude = max_amp * np.exp(-abs(x) / lambdas)\n",
    "    return amplitude * np.cos(omega * x)\n",
    "\n",
    "LAMBDA_PLUS_TRUE = 1.0\n",
    "LAMBDA_MINUS_TRUE = 4\n",
    "MAX_AMP_TRUE = 1.2\n",
    "OMEGA_0_TRUE = 3.0\n",
    "OMEGA_MAX_TRUE = 6.0\n",
    "OMEGA_SIGMA_TRUE = 4.0\n",
    "\n",
    "xi = np.linspace(-15, 5, 200)\n",
    "true_yi = # your code here\n",
    "\n",
    "# your plotting code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Now we add noise to the data, but not by individually moving data points like we did in the past. To better imitate the LIGO project, we'll add low-amplitude sine waves at different frequencies immitating different noises.\n",
    "\n",
    "Note: this will mean that uncertainties on each data point are actually correlated, which violates the assumptions `LMFIT` uses to perform the fit. However, this problem is too complicated for us to handle now, so we ignore it.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "NUMBER_SINES_TO_ADD = 10\n",
    "\n",
    "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n",
    "    # equal to the maximum amplitude of the signal.\n",
    "\n",
    "yi = true_yi.copy()# yi contains the data\n",
    "\n",
    "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
    "    yi += amplitude * np.sin(phase + freq * xi)\n",
    "\n",
    "plt.plot(xi, yi, label='Data')\n",
    "plt.plot(xi, true_yi, label='True')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend();\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_SINES_TO_ADD = 10\n",
    "\n",
    "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n",
    "    # equal to the maximum amplitude of the signal.\n",
    "\n",
    "yi = true_yi.copy()# yi contains the data\n",
    "\n",
    "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
    "    yi += amplitude * np.sin(phase + freq * xi)\n",
    "\n",
    "plt.plot(xi, yi, label='Data')\n",
    "plt.plot(xi, true_yi, label='True')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Make an `LMFIT` model and parameters for this function.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "model = Model(complicated_model_fn)\n",
    "\n",
    "params = Parameters()\n",
    "params.add('lambda_plus', min=0.1, max=5, value=1.1)\n",
    "params.add('lambda_minus', min=0.1, max=5, value=1)\n",
    "params.add('max_amp', min=0, max=2, value=1)\n",
    "params.add('omega_0', min=0, max=5, value=1)\n",
    "params.add('omega_max', min=0, max=10, value=1)\n",
    "params.add('omega_sigma', min=0, max=5, value=1)\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model, Parameters\n",
    "\n",
    "model = Model(complicated_model_fn)\n",
    "\n",
    "params = Parameters()\n",
    "params.add('lambda_plus', min=0.1, max=5, value=1.1)\n",
    "params.add('lambda_minus', min=0.1, max=5, value=1)\n",
    "params.add('max_amp', min=0, max=2, value=1)\n",
    "params.add('omega_0', min=0, max=5, value=1)\n",
    "params.add('omega_max', min=0, max=10, value=1)\n",
    "params.add('omega_sigma', min=0, max=5, value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Using the `model` and `params` variables you made above, fit to the waveform signal. Do not include a weights argument; this will set the uncertainties on all data points equal to each other. Remember to plot the result.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "#your code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "result = model.fit(yi, params, x=xi)\n",
    "print(result.fit_report())\n",
    "result.plot()\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Are you happy with the fit?\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "No; we didn't recover the right parameters and the residuals are pretty large and don't really look like noise.\n",
    "-->\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Let's try to get better fit results. We'll do this by running the fit many times with different initial values and taking the best fit. This is a nice, principled way to get a good fit without knowing the true fit values. \n",
    "\n",
    "First, write a function that generates a new `params` varaible with initial values chosen randomly in the ranges given in the `params_max_min` dictionary.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "params_min_max = {\n",
    "    'lambda_plus': (0.1, 5),\n",
    "    'lambda_minus': (0.1, 5),\n",
    "    'max_amp': (0, 2),\n",
    "    'omega_0': (0, 5),\n",
    "    'omega_max': (0, 10),\n",
    "    'omega_sigma': (0, 5)\n",
    "}\n",
    "params_trues = {\n",
    "    'lambda_plus': LAMBDA_PLUS_TRUE,\n",
    "    'lambda_minus': LAMBDA_MINUS_TRUE,\n",
    "    'max_amp': MAX_AMP_TRUE,\n",
    "    'omega_0': OMEGA_0_TRUE,\n",
    "    'omega_max': OMEGA_MAX_TRUE,\n",
    "    'omega_sigma': OMEGA_SIGMA_TRUE\n",
    "}\n",
    "\n",
    "def get_params():\n",
    "    #your code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "params_min_max = {\n",
    "    'lambda_plus': (0.1, 5),\n",
    "    'lambda_minus': (0.1, 5),\n",
    "    'max_amp': (0, 2),\n",
    "    'omega_0': (0, 5),\n",
    "    'omega_max': (0, 10),\n",
    "    'omega_sigma': (0, 5)\n",
    "}\n",
    "params_trues = {\n",
    "    'lambda_plus': LAMBDA_PLUS_TRUE,\n",
    "    'lambda_minus': LAMBDA_MINUS_TRUE,\n",
    "    'max_amp': MAX_AMP_TRUE,\n",
    "    'omega_0': OMEGA_0_TRUE,\n",
    "    'omega_max': OMEGA_MAX_TRUE,\n",
    "    'omega_sigma': OMEGA_SIGMA_TRUE\n",
    "}\n",
    "\n",
    "def get_params():\n",
    "    params = Parameters()\n",
    "    for p, (p_min, p_max) in params_min_max.items():\n",
    "        value = p_min + (p_max - p_min) * np.random.random(1)\n",
    "        params.add(p, min=p_min, max=p_max, value=v\n",
    "    return params\n",
    "-->\n",
    "\n",
    "<!--end-block-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model, Parameters\n",
    "\n",
    "params_min_max = {\n",
    "    'lambda_plus': (0.1, 5),\n",
    "    'lambda_minus': (0.1, 5),\n",
    "    'max_amp': (0, 2),\n",
    "    'omega_0': (0, 5),\n",
    "    'omega_max': (0, 10),\n",
    "    'omega_sigma': (0, 5)\n",
    "}\n",
    "params_trues = {\n",
    "    'lambda_plus': LAMBDA_PLUS_TRUE,\n",
    "    'lambda_minus': LAMBDA_MINUS_TRUE,\n",
    "    'max_amp': MAX_AMP_TRUE,\n",
    "    'omega_0': OMEGA_0_TRUE,\n",
    "    'omega_max': OMEGA_MAX_TRUE,\n",
    "    'omega_sigma': OMEGA_SIGMA_TRUE\n",
    "}\n",
    "\n",
    "def get_params():\n",
    "    #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Now we write a function that fits using these random parameters, returning the chi squared value and the fit result.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "def fit(empty_arg):\n",
    "    model = Model(complicated_model_fn)\n",
    "    params = get_params()\n",
    "    result = model.fit(yi, params, x=xi)\n",
    "    return result.chisqr, result\n",
    "-->\n",
    "\n",
    "<!--end-block-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(empty_arg):\n",
    "    model = Model(complicated_model_fn)\n",
    "    params = get_params()\n",
    "    result = model.fit(yi, params, x=xi)\n",
    "    return result.chisqr, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Using the `multiprocessing` module to parallelize the operation and make it faster, we perform this fit with different parameters 50 times and store the results for all 50 in the results array.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "from multiprocessing import Pool\n",
    "\n",
    "NUM_FITS = 50\n",
    "\n",
    "with Pool() as pool:\n",
    "    results = pool.map(fit, np.zeros(NUM_FITS))\n",
    "-->\n",
    "\n",
    "<!--end-block-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "NUM_FITS = 50\n",
    "\n",
    "with Pool() as pool:\n",
    "    results = pool.map(fit, np.zeros(NUM_FITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Sort the `results` array generated above by the chi squared value from lowest to highest (the chi squared value is the first element of every item in `results`).\n",
    "\n",
    "Then, for the fit result with the lowest chi squared value (now the first element of sorted `results`), use the fact that the second element of the first item of `results` is the fit result object to print the `fit_report()` and show the `plot()`.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "#your code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "results = sorted(results, key=lambda x:x[0])\n",
    "\n",
    "print(results[0][1].fit_report())\n",
    "results[0][1].plot();\n",
    "-->\n",
    "\n",
    "<!--end-block-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "For each parameter of the best fit result, display the true value (stored in `params_trues`), the fit value, the fit uncertainty, and the the difference between the true and fit values divided by the fit uncertainty.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "#your code here\n",
    "-->\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "for param, info in results[0][1].params.items():\n",
    "    print(f\"{param}:\\tTrue: {float(params_trues[param])}\\tFit: {info.value} +/- {info.stderr}\"+\\\n",
    "          f\"\\tSigmas: {abs(info.value - params_trues[param]) / info.stderr}\")\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Are you happier with the fit now? What are some other things you might do to get an even better result?\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "Yes; the true values are much closer to the fit values and the residuals look better. You might improve results by:\n",
    "- fitting over more initial parameters than 50\n",
    "- acknowledge uncertainty correlation\n",
    "- change the model function parameterization so that each parameter is more independent.\n",
    "- separate the hard-to-fit-for parts of the model function from the easy-to-fit-for so that the error bars on the easy-to-fit-for parameters are small\n",
    "-->\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 3.4 Interpreting bugs with `LMFIT`\n",
    "\n",
    "Let's walk through a couple common bugs you might encounter when using `LMFIT`, so you know what causes them. (These are bugs in your code, not `LMFIT`).\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "### Bug 1\n",
    "\n",
    "Let's run the code from example 3.2, but take out the parameter limits on $k$. (Make sure you run the 3.2 blocks of code before running this one.)\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "model = Model(model_fn)\n",
    "params = Parameters()\n",
    "params.add('k')\n",
    "params.add('a', min=0, max=3, value=2)\n",
    "\n",
    "result = model.fit(y, params, x=x, weights=1/y_unc);\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "result.plot();\n",
    "\n",
    "#THROWS AN ERROR\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model, Parameters\n",
    "\n",
    "model = Model(model_fn)\n",
    "params = Parameters()\n",
    "params.add('k')\n",
    "params.add('a', min=0, max=3, value=2)\n",
    "\n",
    "result = model.fit(y, params, x=x, weights=1/y_unc);\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "result.plot();\n",
    "\n",
    "#THROWS AN ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "What was the error? (Remember the phrase `generated NaN values`) What arguments can you add back to the $k$ parameter to fix this error?\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "The nan error is a signifier that either your model function is incorrect or it is being used for parameters you did not intend to use it for. By setting the initial value of k closer to the true value, you resolve the problem. This error can also happen when your parameters are degenerate, as $k$ is here; $-k$ and $k$ give the same function.\n",
    "-->\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "### Bug 2\n",
    "\n",
    "Let's try fitting the wrong model to data. We'll generate data according to the function $f(x)=x^2$, but fit a Gaussian model instead.\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "import numpy as np\n",
    "from lmfit.models import GaussianModel\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# Linear data\n",
    "xi = np.array([-2, -1, 0, 1, 2])\n",
    "yerr = np.array([0.3, 0.4, 0.45, 0.35, 0.6])\n",
    "yi = xi**2 +yerr*np.random.normal(xi.shape)\n",
    "\n",
    "# Gaussian model\n",
    "model = GaussianModel()\n",
    "\n",
    "results = model.fit(yi, x=xi, weights = 1/yerr);\n",
    "\n",
    "print(results.fit_report())\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lmfit.models import GaussianModel\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# Quadratic data\n",
    "xi = np.array([-2, -1, 0, 1, 2])\n",
    "yerr = np.array([0.3, 0.4, 0.45, 0.35, 0.6])\n",
    "yi = xi**2 +yerr*np.random.normal(xi.shape)\n",
    "\n",
    "# Gaussian model\n",
    "model = GaussianModel()\n",
    "\n",
    "results = model.fit(yi, x=xi, weights = 1/yerr);\n",
    "\n",
    "print(results.fit_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Was an error thrown? Look more closely at the fit report. What is the warning line? What does it signify?\n",
    "\n",
    "Add the line `results.plot();` to the above block of code. Does this make it easier to diagnose the problem?\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "`##  Warning: uncertainties could not be estimated.` It indicates that your fit was quite bad, as do your chi squared and reduced chi-squared values. By looking at those or by plotting the function, the poor fit quality becomes more recognizable.\n",
    "-->\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "### Bug 3\n",
    "\n",
    "`LMFIT` relies on the fact that your model function needs to handle `np` arrays. What happens if yours doesn't?\n",
    "\n",
    "<!--\n",
    "#initial code\n",
    "import numpy as np\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "TRUE_HEIGHT = 1.0\n",
    "\n",
    "def heaviside(x, height):\n",
    "    if x > 0:\n",
    "        return height\n",
    "    return 0.0\n",
    "\n",
    "xi = np.linspace(-5, 5, 10)\n",
    "try:\n",
    "    yi = heaviside(xi, TRUE_HEIGHT)\n",
    "except:\n",
    "    yi = np.array([heaviside(x, TRUE_HEIGHT) for x in xi])\n",
    "yerr = np.random.random(len(xi)) * 0.4 + 0.1\n",
    "yi += np.random.randn(len(xi)) * yerr\n",
    "\n",
    "model = Model(heaviside)\n",
    "params = Parameters()\n",
    "params.add('height', min=0.1, max=10, value=2)\n",
    "\n",
    "results = model.fit(yi, params, x=xi, weights = 1/yerr);\n",
    "\n",
    "print(results.fit_report())\n",
    "\n",
    "results.plot();\n",
    "\n",
    "#THROWS AN ERROR\n",
    "-->\n",
    "\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lmfit import Model, Parameters\n",
    "\n",
    "TRUE_HEIGHT = 1.0\n",
    "\n",
    "def heaviside(x, height):\n",
    "    if x > 0:\n",
    "        return height\n",
    "    return 0.0\n",
    "\n",
    "xi = np.linspace(-5, 5, 10)\n",
    "try:\n",
    "    yi = heaviside(xi, TRUE_HEIGHT)\n",
    "except:\n",
    "    yi = np.array([heaviside(x, TRUE_HEIGHT) for x in xi])\n",
    "yerr = np.random.random(len(xi)) * 0.4 + 0.1\n",
    "yi += np.random.randn(len(xi)) * yerr\n",
    "\n",
    "model = Model(heaviside)\n",
    "params = Parameters()\n",
    "params.add('height', min=0.1, max=10, value=2)\n",
    "\n",
    "results = model.fit(yi, params, x=xi, weights = 1/yerr);\n",
    "\n",
    "print(results.fit_report())\n",
    "\n",
    "results.plot();\n",
    "\n",
    "#THROWS AN ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "What was the error? Modify the model function so that it works for numpy arrays. There are several ways to do this, with varying levels of computational speed.\n",
    "\n",
    "Remember that as a fallback, you can always manually turn a python list into a numpy array by calling `np.array(list)` where `list` is a python list.\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "The error was this `a.any()` / `a.all()`. This error is a bit of a red herring; I think it's simpler to change your fit function to the following.\n",
    "\n",
    "```\n",
    "def heaviside(x, height):\n",
    "    return np.array([height if x_val > 0 else 0 for x_val in x])\n",
    "```\n",
    "-->\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
